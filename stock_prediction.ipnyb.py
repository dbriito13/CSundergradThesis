# -*- coding: utf-8 -*-
"""StockBSHprediction (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r2cRPOW7d09Znqh5wXDCH7QAqxizCp8z

# Imports
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd drive/MyDrive/Tfg21DB/code/codigoDefinitivo/
# %ls

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# from datetime import datetime as dt
# import pandas as pd
# import pandas_datareader.data as web
# import requests
# import io
# from datetime import datetime as date
# import matplotlib.pyplot as plt
# import matplotlib as mpl
# from matplotlib import style
# import seaborn as sns
# from xgboost import XGBClassifier
# import sklearn as sk
# import numpy as np
# import tensorflow as tf
# from tensorflow import keras
# from tensorflow.keras import layers
# import re
# import json
# import random
# !pip install pypi-install
# !pip install mplfinance
# !pip install tqdm
# import mplfinance as mplf
# import warnings
# from mplfinance.original_flavor import candlestick_ohlc
# from bs4 import BeautifulSoup
# from collections import Counter
# from sklearn import model_selection
# from sklearn.ensemble import RandomForestClassifier
# from sklearn.metrics import accuracy_score, precision_score, confusion_matrix, classification_report
# from collections import Counter
# from sklearn.svm import SVC
# from sklearn.model_selection import KFold, GridSearchCV
# from sklearn.neural_network import MLPClassifier
# from os.path import exists

style.use('ggplot')
plt.rcParams['figure.figsize'] = [20, 10]

pd.options.mode.chained_assignment = None
warnings.filterwarnings("ignore", message=r"Passing", category=FutureWarning)

"""#Auxiliary functions"""

def print_accuracy(model, X_train, X_test, y_train, y_test):
  print("========================================")
  y_train_preds = model.predict(X_train)
  acc_train = accuracy_score(y_train, y_train_preds) * 100
  y_test_preds = model.predict(X_test)
  acc_test = accuracy_score(y_test, y_test_preds) * 100
  print(f"Train accuracy: {acc_train} %")
  print(f"Test accuracy: {acc_test} %")
  print("========================================")
  return y_test_preds

def print_precision(model, X_train, X_test, y_train, y_test):
  print("========================================")
  y_train_preds = model.predict(X_train)
  acc_train = precision_score(y_train, y_train_preds) * 100
  y_test_preds = model.predict(X_test)
  acc_test = precision_score(y_test, y_test_preds) * 100
  print(f"Train precision: {acc_train} %")
  print(f"Test precision: {acc_test} %")
  print("========================================")
  return y_test_preds

def get_sp500_stocks():
  table=pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')
  df = table[0]
  return df['Symbol']

def clean_sp500_stocks():
  stocks = []
  for stock in get_sp500_stocks():
    if stock == 'BF.B':
      stocks.append("BF-B")
    elif stock == 'BRK.B':
      stocks.append("BRK-B")
    else:
      stocks.append(stock)
  return stocks

def fetch_yahoo(stock_symbol):
  headers = {
      'User-Agent': 'Mozilla/5.0'
  }
  url = "https://query1.finance.yahoo.com/v7/finance/download/"
  url += str(stock_symbol)
  url += "?period1=1030060800&period2=1661212800&interval=1d&events=history&includeAdjustedClose=true"
  r = requests.get(url, headers=headers)
  pds = pd.read_csv(io.StringIO(r.text), index_col=0, parse_dates=True)
  return pds

def fetch_ratio(ratio, stock_symbol, v_i, trailing=False, debug=False):
  statements = {'v1': 'balance-sheet', 'v2': 'income-statement', 'v3': 'price-ratios'}
  data = []
  statement = statements[v_i]
  if trailing == True:
     #find ratio in the table and choose statement accordingly
     if ratio in v1_ratios:
       statement = 'balance-sheet'
     if ratio in v2_ratios:
       statement = 'income-statement'
     else:
       statement = 'price-ratios'
  url = f"https://www.macrotrends.net/assets/php/fundamental_iframe.php?t={stock_symbol}&type={ratio}&statement={statement}&freq=Q"
  if ratio == 'profit-margins':
      url = f"https://www.macrotrends.net/assets/php/fundamental_metric.php?t={stock_symbol}&chart=profit-margin"
  html_doc = requests.get(url).text
  if debug == True: print(url)
  res = re.search(r"chartData = (\[\{.*?\}\])", html_doc)
  if res is None:
    return None
  res = res.group(1)
  res = json.loads(res)
  for entry in res:
    data.append((entry['date'], stock_symbol, entry[v_i]))

  if trailing == True:
    ratio = ratio + "_12M"
  return pd.DataFrame(data, columns=['Date', 'Ticker', ratio])

v3_ratios = ['pe-ratio', 
          'price-sales', 
          'price-book', 
          'price-fcf', 
          'current-ratio', 
          'quick-ratio', 
          'debt-equity-ratio', 
          'roe', 'roa', 
          'return-on-tangible-equity', 
          'ebitda-margin',
          'operating-margin']
trailing_ratios = ['eps-earnings-per-share-diluted',
                   'operating-income',
                   'ebitda',
                   'gross-profit',
                   ''
]
v1_ratios = ['total-assets',
             'total-liabilities',
             'total-share-holder-equity',
             'long-term-debt',
             'shares-outstanding',
]

v2_ratios = [
          'eps-earnings-per-share-diluted',
          'net-profit-margin',
          'net-income',
          'ebitda',
          'operating-income',
          'gross-profit',
          'profit-margins',
          'eps-basic-net-earnings-per-share',
]

def fetch_ratios(stock_symbol, debug=False):
  df = pd.DataFrame()
  for ratio in v1_ratios:
    if debug == True: print(f"fetching {ratio} for {stock_symbol}")
    df_ratio = fetch_ratio(ratio, stock_symbol, 'v1', debug=debug)
    if df_ratio is not None:
      if df.empty:
        df = df_ratio
      else:
        df = pd.merge(df, df_ratio)
  for ratio in v2_ratios:
    if debug == True: print(f"fetching {ratio} for {stock_symbol}")
    df_ratio = fetch_ratio(ratio, stock_symbol, 'v2', debug=debug)
    if df_ratio is not None:
      df = pd.merge(df, df_ratio)
  for ratio in v3_ratios:
    if debug == True: print(f"fetching {ratio} for {stock_symbol}")
    df_ratio = fetch_ratio(ratio, stock_symbol, 'v3', debug=debug)
    if df_ratio is not None:
      df = pd.merge(df, df_ratio)
  for ratio in trailing_ratios:
    if debug == True: print(f"fetching {ratio} for {stock_symbol}")
    df_ratio = fetch_ratio(ratio, stock_symbol, 'v1', True, debug=debug)
    if df_ratio is not None:    
      df = pd.merge(df, df_ratio)
  return df

def fetch_dataframes(stock_symbol):
  if stock_symbol == 'BF.B':
    df_prices = fetch_yahoo("BF-B")
  elif stock_symbol == 'BRK.B':
    df_prices = fetch_yahoo("BRK-B")
  else:
    df_prices = fetch_yahoo(stock_symbol)
  df_ratios = fetch_ratios(stock_symbol)
  df_ratios.set_index('Date', inplace=True)
  df_prices.drop(['Open', 'High', 'Low', 'Close', 'Volume'], axis=1, inplace=True)
  start_date = str(df_prices.index[0])
  end_date = str(df_prices.index[-1])
  idx = pd.date_range(start_date, end_date)
  df_prices = df_prices.reindex(idx)
  df_prices.ffill(inplace=True)
  return df_prices, df_ratios

def fetch_data(stock_symbol):
  df_p, df_r = fetch_dataframes(stock_symbol)
  df_r['Adj Close'] = np.nan
  all_dates = [str(date)[:10] for date in df_p.index]
  for date in df_r.index:
    all_dates.remove(date)
  for date in all_dates:
    df_p.drop(date, inplace=True)
  df_r['Adj Close'] = df_p['Adj Close'].values
  #Now we create the column of the annual change
  df_r['Yearly Change (%)'] = (df_r['Adj Close'].shift(-4) - df_r['Adj Close']) / (df_r['Adj Close']) * 100.0
  return df_r

"""#Getting the stock data"""

from tqdm import tqdm
def get_sp500_stock_data(debug):
  df = pd.DataFrame()
  sp500_tickers = get_sp500_stocks()

  for i in tqdm(range(len(sp500_tickers))):
    ticker = sp500_tickers[i]
    if debug == True: print("Getting data for ticker: " + ticker)
    df_ticker = pd.DataFrame()
    df_ticker['Ticker'] = ticker
    df_ticker = fetch_data(ticker)
    if debug == True: print("Size of ticker's data: "+str(len(df_ticker)))
    df = pd.concat([df, df_ticker])
  return df

if exists('sp500_data.csv') == True:
  df = pd.read_csv('sp500_data.csv', index_col='Date')
  df.drop(df.filter(regex="Unname"),axis=1, inplace=True)
else:
  df = get_sp500_stock_data(False)
  df.to_csv('sp500_data.csv', encoding='utf-8')

df.shape

"""#Cleaning the DataFrame"""

#Also the last 4 values for each stock can't be used in our dataset since we donÂ´t have data for a year after said dates, so we drop them
df.fillna(0, inplace=True)

"""#Preparing Dataset for Machine Learning"""

#Set the threshold over which we will label our stocks with a 1, that is, stocks that after a year grow more than EXPECTED_RETURN % will be labeled with 1, all others with 0.
EXPECTED_RETURN = 12.5

df['Target'] = (df['Yearly Change (%)'] > EXPECTED_RETURN).astype(int)
df_backtest = df.copy(deep=True)
df.drop(columns='Yearly Change (%)', inplace=True)

df.sort_index(axis = 0, inplace=True)

def extract_features_target(df, debug=False):
  '''
  From a given dataframe it separates it into an array of features and an array of target variables
  Entry: df: dataframe, debug: flag to print status
  Returns: X: array of features, y: list of targets
  '''
  features = df.columns.tolist()
  features.remove('Target')
  features.remove('Adj Close')
  features.remove('Ticker')
  if debug == True:
    print(f"The dataset has {len(features)} features.")
  return df[features].values, df['Target'].values

plt.figure()
sns.countplot(x='Target', data=df)
plt.title('Target Variable Distribution')
plt.show()

df_corr = df.copy(deep=True)
df_corr.drop(columns='Target', inplace=True)
df_corr.drop(columns='Adj Close', inplace=True)

fig = plt.figure(figsize=(20,20), dpi = 480)
sns.heatmap(df_corr.corr(), annot = True, fmt = '.2f')

"""#Models"""

def accuracy_random(y_train, y_test, debug=False):
  '''
  Given a train and test targets, it prints the accuracy the model would have
  achieved if we had just predicted the majority class in the train dataset
  Entry: y_train: train targets, y_test: test targets, debug
  Returns:
  '''
  train_mc = Counter(y_train).most_common(1)[0][0]
  if debug == True:
    print(f"The most common target class in the train dataset is {train_mc} with {dict(Counter(y_train)).get(train_mc)} / {len(y_train)}")
  num_occ = dict(Counter(y_test)).get(train_mc)
  rand_acc = num_occ / (len(y_test) * 1.0) * 100.0
  print(f"The accuracy of a model that predicts the majority class in the train dataset would be {rand_acc} %")

def predict_RandomForest(df, debug=False):
  if debug == True:
    X, y = extract_features_target(df, True)
  else:
    X, y = extract_features_target(df)
  X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25, random_state=42, shuffle=False)
  accuracy_random(y_train, y_test, debug)

  rf = RandomForestClassifier(n_estimators=1000, max_depth=15)
  rf.fit(X_train, y_train)
  print("\n\t Random Forest Results \t")
  y_test_preds = print_accuracy(rf, X_train, X_test, y_train, y_test)
  print_precision(rf, X_train, X_test, y_train, y_test)
  cm = confusion_matrix(y_test, y_test_preds)
  s = sns.heatmap(cm, annot=True)
  s.set(xlabel='Predicted', ylabel='True')

  
  return y_test_preds, rf

def predict_SVM(df, debug=False):
  if debug == True:
    X, y = extract_features_target(df, True)
  else:
    X, y = extract_features_target(df)
  X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25, random_state=42, shuffle=False)
  accuracy_random(y_train, y_test, debug)

  sv = SVC()
  sv.fit(X_train, y_train)
  print("\n\t SVM Results \t")
  y_test_preds = print_accuracy(sv, X_train, X_test, y_train, y_test)
  print_precision(sv, X_train, X_test, y_train, y_test)
  cm = confusion_matrix(y_test, y_test_preds)
  s = sns.heatmap(cm, annot=True)
  s.set(xlabel='Predicted', ylabel='True')
  
  return y_test_preds, sv

from sklearn.model_selection import GridSearchCV

def predict_MLP(df, debug=False):
  if debug == True:
    X, y = extract_features_target(df, True)
  else:
    X, y = extract_features_target(df)
  X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25, random_state=42, shuffle=False)
  accuracy_random(y_train, y_test, debug)

  parameter_space = {
    'hidden_layer_sizes': [(10,), (50,), (100,), (10,50), (50,50), (100,50), (50,50,50), (50,100,50),],
    'activation': ['tanh','relu'],
    'solver': ['adam'],
    'alpha': [0.0001],
    'learning_rate': ['constant'],
  }

  mlp = MLPClassifier(max_iter = 500)
  mlp = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=[(slice(None), slice(None))], scoring='accuracy', verbose=10)
  mlp.fit(X_train, y_train)

  if debug == True:
    print(mlp.best_params_)

  print("\n\t Multi Layer Perceptron Results \t")
  y_test_preds = print_accuracy(mlp, X_train, X_test, y_train, y_test)
  print_precision(mlp, X_train, X_test, y_train, y_test)
  cm = confusion_matrix(y_test, y_test_preds)
  s = sns.heatmap(cm, annot=True)
  s.set(xlabel='Predicted', ylabel='True')
  
  return y_test_preds, mlp

predictions, model_rf = predict_RandomForest(df, False)

predictions_svm, model_svm = predict_SVM(df, False)

predictions_mlp, model_mlp = predict_MLP(df, True)

"""# Backtesting"""

def fetch_sp500(date_start, date_end, ready=False):
  headers = {
      'User-Agent': 'Mozilla/5.0'
  }

  url = "https://query1.finance.yahoo.com/v7/finance/download/^GSPC"
  x = int(date.strptime(date_start, '%Y-%m-%d').strftime("%s"))
  y = int(date.strptime(date_end, '%Y-%m-%d').strftime("%s"))
  url += "?period1=" + str(x) + "&period2=" + str(y) + \
      "&interval=1d&events=history&includeAdjustedClose=true"

  r = requests.get(url, headers=headers)
  pds = pd.read_csv(io.StringIO(r.text), index_col=0, parse_dates=True)
  if ready == True:
    return pds['Close'].values.reshape(-1,1)
  else:
    return pds

def get_sp500_ret(df):
  start = df.index[0]
  end = df.index[-1]
  sp500 = fetch_sp500(start, end, True)
  return ((sp500[-1]-sp500[0])/sp500[0]*100.0), start, end

def print_backtest(n_trades, acc_ret, n_succ_trades, invested, df):
  sp500, start, end = get_sp500_ret(df)
  print(f"\t Backtest Results {start} - {end} \t")
  print("=================================================================")
  print(f"Invested: {invested}$")
  print(f"Return : {acc_ret}$")
  print(f"Return (%): {acc_ret/invested * 100.0}%")
  print(f"Number of Trades: {n_trades}")
  print(f"S&P500 Return: {sp500[0]}")
  print(f"alpha: {acc_ret / invested * 100.0 - sp500[0]}%")
  print("=================================================================")

def perform_backtest(model, X, df):  
  predictions = model.predict(X).tolist()
  df['Predicted'] = predictions
  df['Return'] = np.where(
      df['Predicted'] == 1, 
      df['Adj Close 1y'] - df['Adj Close'],
      0)
  n_trades = df['Predicted'].sum()
  acc_ret = df['Return'].sum()
  n_succ_trades = df['Return'].gt(0.0).sum()
  invested = df.loc[df['Predicted'] == 1, 'Adj Close'].sum()
  return n_trades, acc_ret, n_succ_trades, invested

def backtest(model, df_test, percentage):
  df = df_test.tail(round(len(df_test)*percentage))
  df.sort_index(axis = 0, inplace=True)

  df['Adj Close 1y'] = df['Adj Close'] * (1 + df['Yearly Change (%)'] / 100.0)
  df.drop(columns='Yearly Change (%)', inplace=True)
  df_aux = df.drop(columns='Adj Close 1y')
  X,_ = extract_features_target(df_aux)

  n_trades, acc_ret, n_succ_trades, invested = perform_backtest(model, X, df)
  print_backtest( n_trades, acc_ret, n_succ_trades, invested, df)

df = pd.read_csv('sp500_data.csv', index_col='Date')
df.drop(df.filter(regex="Unname"),axis=1, inplace=True)
df.fillna(0, inplace=True)
EXPECTED_RETURN = 12.5
df['Target'] = (df['Yearly Change (%)'] > EXPECTED_RETURN).astype(int)
df.sort_index(axis = 0, inplace=True)

"""## Backtesting for RandomForest"""

for percentage in [0.1, 0.125, 0.175, 0.25]:
  backtest(model_rf, df, percentage)

"""##Backtesting for SVM"""

for percentage in [0.1, 0.125, 0.175, 0.25]:
  backtest(model_svm, df, percentage)

"""##Backtesting for MLP"""

for percentage in [0.1, 0.125, 0.175, 0.25]:
  backtest(model_mlp, df, percentage)

